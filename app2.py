
import streamlit as st
import pandas as pd
import tempfile
import os
import base64
import json
import google.generativeai as genai
from google.api_core.exceptions import GoogleAPIError
import io
import time
import re
from datetime import datetime
from PIL import Image
import PyPDF2

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PDF/ì´ë¯¸ì§€ í‘œ ì¶”ì¶œ ë„êµ¬",
    page_icon="ğŸ“Š",
    layout="centered",
    initial_sidebar_state="expanded"
)

# API í‚¤ ì„¤ì •
def get_api_key():
    try:
        return st.secrets["gemini"]["api_key"]
    except:
        if "api_key" in st.session_state and st.session_state["api_key"]:
            return st.session_state["api_key"]
        return None

# Gemini API ì„¤ì •
def setup_gemini_api(api_key):
    try:
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        st.error(f"Gemini API ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return False

# í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ íŒŒì¼ëª…ì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
def get_timestamp_filename():
    """í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ 'YYYY-MM-DD_HHMMSS' í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    now = datetime.now()
    return now.strftime("%Y-%m-%d_%H%M%S")

# PDF í…Œì´ë¸” êµ¬ì¡°ì™€ ìœ ì‚¬í•˜ê²Œ ë°ì´í„° ì¬êµ¬ì„±
def restructure_table_data(df):
    """
    Geminiê°€ ì¶”ì¶œí•œ ë‹¨ì¼ í–‰ CSV ë°ì´í„°ë¥¼ PDF í…Œì´ë¸” êµ¬ì¡°ì™€ ìœ ì‚¬í•˜ê²Œ ì¬êµ¬ì„±
    
    Args:
        df (DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„
    
    Returns:
        DataFrame: ì¬êµ¬ì„±ëœ ë°ì´í„°í”„ë ˆì„
    """
    try:
        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°˜í™˜
        if df.empty or len(df) == 0:
            return df
            
        # ì²« ë²ˆì§¸ í–‰ì˜ ë°ì´í„°ë§Œ ì‚¬ìš© (ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì¼ í–‰ìœ¼ë¡œ ì¶”ì¶œë¨)
        if len(df) == 1:
            row_data = df.iloc[0]
        else:
            # ì—¬ëŸ¬ í–‰ì´ ìˆëŠ” ê²½ìš° (ë“œë¬¸ ê²½ìš°) ì²« í–‰ ì‚¬ìš©
            row_data = df.iloc[0]
        
        # ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ êµ¬ì¡° ì •ì˜
        # ìƒë‹¨ í…Œì´ë¸” (ê¸°ë³¸ ì •ë³´)
        header1 = ['í˜¸ì‹¤', 'ê³„ì•½ì', 'ë©´ì (ã¡)', 'ë¶„ì–‘ëŒ€ê¸ˆ']
        data1 = []
        
        # í–‰ 1 (í˜¸ì‹¤, ê³„ì•½ë²ˆí˜¸, ê³„ì•½ì, ë©´ì )
        if 'í˜¸ì‹¤' in df.columns and 'ê³„ì•½ì' in df.columns:
            data1.append([
                row_data.get('í˜¸ì‹¤', ''),
                row_data.get('ê³„ì•½ì', ''),
                row_data.get('ë©´ì (ã¡)', ''),
                row_data.get('ë¶„ì–‘ëŒ€ê¸ˆ', '')
            ])
        else:
            # ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¸ ê²½ìš° ì²˜ë¦¬
            columns = df.columns.tolist()
            if len(columns) >= 4:
                data1.append([row_data[columns[0]], row_data[columns[1]], 
                             row_data[columns[2]], row_data[columns[5]]])
            else:
                # ì»¬ëŸ¼ì´ ë¶€ì¡±í•œ ê²½ìš° ë¹ˆ ë°ì´í„° ì‚½ì…
                data1.append(['', '', '', ''])
        
        top_table = pd.DataFrame(data1, columns=header1)
        
        # í•˜ë‹¨ í…Œì´ë¸” (ë‚©ë¶€ ì •ë³´)
        header2 = ['êµ¬ë¶„', 'ë‚©ë¶€í• ê¸ˆì•¡(ì—°ì²´ë£Œí¬í•¨)', 'ë‚©ë¶€ê¸ˆì•¡', 'ë‚©ë¶€ì¼']
        data2 = []
        
        # ê³„ì•½ê¸ˆ
        data2.append(['ê³„ì•½ê¸ˆ', 
                     row_data.get('ë‚©ë¶€í• ê¸ˆì•¡(ì—°ì²´ë£Œí¬í•¨)', ''), 
                     row_data.get('ë‚©ë¶€ê¸ˆì•¡', ''),
                     row_data.get('ë‚©ë¶€ì¼', '')])
        
        # ì¤‘ë„ê¸ˆ 1~4ì°¨
        for i in range(1, 5):
            data2.append([f'ì¤‘ë„ê¸ˆ {i}ì°¨',
                         row_data.get(f'ë‚©ë¶€í• ê¸ˆì•¡(ì—°ì²´ë£Œí¬í•¨).{i}', ''),
                         row_data.get(f'ë‚©ë¶€ê¸ˆì•¡.{i}', ''),
                         row_data.get(f'ë‚©ë¶€ì¼.{i}', '')])
        
        # ì”ê¸ˆ
        data2.append(['ì”ê¸ˆ',
                     row_data.get('ë‚©ë¶€í• ê¸ˆì•¡(ì—°ì²´ë£Œí¬í•¨).5', ''),
                     row_data.get('ë‚©ë¶€ê¸ˆì•¡.5', ''),
                     row_data.get('ë‚©ë¶€ì¼.5', '')])
        
        bottom_table = pd.DataFrame(data2, columns=header2)
        
        # í•„ìš”í•œ ê²½ìš° ë‘ í…Œì´ë¸”ì„ ê²°í•©
        # ì—¬ê¸°ì„œëŠ” ë³„ë„ë¡œ ë°˜í™˜í•˜ì—¬ ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆê²Œ í•¨
        return {
            'top_table': top_table,
            'bottom_table': bottom_table,
            'combined': pd.concat([top_table, pd.DataFrame([['---', '---', '---', '---']], columns=header1), bottom_table], ignore_index=True)
        }
        
    except Exception as e:
        print(f"í…Œì´ë¸” ì¬êµ¬ì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return df

# ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜
def process_image_file(image_file):
    """
    ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë°”ì´íŠ¸ë¡œ ë°˜í™˜
    
    Args:
        image_file: Streamlitì˜ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼
        
    Returns:
        bytes: ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì˜ ë°”ì´íŠ¸
    """
    try:
        # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
        image_bytes = io.BytesIO(image_file.getvalue())
        image = Image.open(image_bytes)
        
        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
        width, height = image.size
        
        # ì´ë¯¸ì§€ ìµœì í™” ë° í’ˆì§ˆ ê°œì„ 
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ì€ ê²½ìš° í™•ëŒ€
        min_dimension = 1200  # ìµœì†Œ ê¶Œì¥ í¬ê¸°
        if width < min_dimension or height < min_dimension:
            scale_factor = max(min_dimension / width, min_dimension / height)
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            st.info(f"ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ ì„ ìœ„í•´ í¬ê¸°ë¥¼ ì¡°ì •í–ˆìŠµë‹ˆë‹¤: {width}x{height} â†’ {new_width}x{new_height}")
        
        # ì´ë¯¸ì§€ ì„ ëª…ë„ ê°œì„  (í•„ìš”í•œ ê²½ìš°)
        from PIL import ImageEnhance
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.2)  # ì•½ê°„ì˜ ì„ ëª…ë„ í–¥ìƒ
        
        # ëŒ€ë¹„ í–¥ìƒ
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.1)  # ì•½ê°„ì˜ ëŒ€ë¹„ í–¥ìƒ
            
        # ê³ í’ˆì§ˆ ë°”ì´íŠ¸ë¡œ ë³€í™˜
        output_bytes = io.BytesIO()
        image.save(output_bytes, format='PNG', compress_level=0)  # ìµœëŒ€ í’ˆì§ˆ
        output_bytes.seek(0)
        
        return output_bytes.getvalue()
        
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# PDFì—ì„œ ì²« í˜ì´ì§€ë§Œ ì¶”ì¶œ
def extract_first_page_pdf(pdf_file):
    """PDFì—ì„œ ì²« í˜ì´ì§€ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆ PDFë¡œ ë°˜í™˜"""
    try:
        # ì…ë ¥ PDF ì½ê¸°
        pdf_bytes = io.BytesIO(pdf_file.getvalue())
        reader = PyPDF2.PdfReader(pdf_bytes)
        
        if len(reader.pages) == 0:
            st.error("PDF íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None
            
        # ìƒˆ PDF ìƒì„±
        writer = PyPDF2.PdfWriter()
        # ì²« í˜ì´ì§€ë§Œ ì¶”ê°€
        writer.add_page(reader.pages[0])
        
        # ìƒˆ PDFë¥¼ ë°”ì´íŠ¸ë¡œ ì €ì¥
        output_bytes = io.BytesIO()
        writer.write(output_bytes)
        output_bytes.seek(0)
        
        return output_bytes.getvalue()
        
    except Exception as e:
        st.error(f"PDF ì²« í˜ì´ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


# í•µì‹¬ í•¨ìˆ˜: íŒŒì¼ì„ Gemini APIì— ì§ì ‘ ì „ì†¡í•˜ì—¬ í‘œ ì¶”ì¶œ
def extract_tables_from_file_directly(file_bytes, file_type, gemini_model, max_retries=3):
    """íŒŒì¼ì„ ì§ì ‘ Gemini APIì— ì „ì†¡í•˜ì—¬ í‘œ ì¶”ì¶œ"""
    try:
        # API í‚¤ í™•ì¸
        api_key = get_api_key()
        if not api_key:
            st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
            
        # API í‚¤ ì„¤ì •
        if not setup_gemini_api(api_key):
            st.error("Gemini API ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return []
        
        # ê³ ê¸‰ ì„¤ì •ì— ë”°ë¥¸ ëª¨ë¸ êµ¬ì„±
        temperature = 0.0
        max_tokens = 30000
        
        if 'extraction_quality' in st.session_state:
            if st.session_state.extraction_quality == "ë¹ ë¦„":
                temperature = 0.2
                max_tokens = 12000
            elif st.session_state.extraction_quality == "ê· í˜•":
                temperature = 0.1
                max_tokens = 20000
            else:  # ë†’ì€ í’ˆì§ˆ
                temperature = 0.0
                max_tokens = 30000
        
        # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ë° MIME íƒ€ì… ì„¤ì •
        if file_type == "pdf":
            prompt = """
            ì´ PDF ë¬¸ì„œì—ì„œ ëª¨ë“  í‘œë¥¼ ì°¾ì•„ ì •í™•í•œ CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. 
            PDFê°€ 90ë„ íšŒì „ë˜ì–´ ìˆë”ë¼ë„ ì•Œì•„ì„œ ì¸ì‹í•˜ê³  í‘œì˜ ë‚´ìš©ì„ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

            ì¶”ì¶œ ì‹œ ë‹¤ìŒ ì§€ì¹¨ì„ ì² ì €íˆ ë”°ë¼ì£¼ì„¸ìš”:
            1. ë¬¸ì„œì— ìˆëŠ” ëª¨ë“  í‘œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ëª¨ë“  ìœ í˜•ì˜ í‘œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
               - ì¬ë¬´ì œí‘œ/ì¬ë¬´ìƒíƒœí‘œ/ëŒ€ì°¨ëŒ€ì¡°í‘œ
               - ì†ìµê³„ì‚°ì„œ
               - í˜„ê¸ˆíë¦„í‘œ
               - ìë³¸ë³€ë™í‘œ
               - ì£¼ìš” íˆ¬ìì§€í‘œ
               - ì£¼ì„ì‚¬í•­ê³¼ ë¶€ê°€ì„¤ëª…ì´ í¬í•¨ëœ í‘œ
               - ê·¸ ì™¸ ëª¨ë“  ìˆ«ìë‚˜ ë°ì´í„°ê°€ í¬í•¨ëœ í‘œ

            2. ê° í‘œì˜ êµ¬ì¡°ì™€ í˜•ì‹ì„ ì •í™•í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”:
               - ì—°ë„ë³„ ì¹¼ëŸ¼ êµ¬ì¡° ìœ ì§€ (2016, 2017, 2018, 2019, 2020ë…„ ë“± ëª¨ë“  ì—°ë„ í¬í•¨)
               - ê¸ˆì•¡ ë‹¨ìœ„(ë°±ë§Œì›, ì–µì› ë“±) í‘œì‹œ í¬í•¨
               - ëª¨ë“  í•­ëª©ëª…(ë§¤ì¶œì•¡, ì˜ì—…ì´ìµ, ìì‚°ì´ê³„ ë“±)ì„ ì •í™•íˆ í¬í•¨
               - ìŒìˆ˜ ê°’ì€ ì›ë˜ í˜•íƒœë¡œ ìœ ì§€(-ê¸°í˜¸ í¬í•¨)
               - ë¹„ìœ¨(%) ê°’ì€ ì›ë˜ í˜•íƒœë¡œ ìœ ì§€(% ê¸°í˜¸ í¬í•¨ ê°€ëŠ¥)
            
            3. í‘œ ì „ì²´ë¥¼ ì™„ì „íˆ ì¶”ì¶œí•˜ì„¸ìš”:
               - í‘œì˜ ëª¨ë“  í–‰ê³¼ ì—´ì´ ëˆ„ë½ ì—†ì´ ì¶”ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
               - í‘œì˜ ì œëª©/í—¤ë”/ë¶€ì œëª©ë„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
               - í‘œ í•˜ë‹¨ì˜ ì£¼ì„ì´ë‚˜ ì¶œì²˜ ì •ë³´ë„ ê°€ëŠ¥í•˜ë©´ í¬í•¨í•˜ì„¸ìš”
            
            4. ê° í‘œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ "TABLE_START"ë¡œ ì‹œì‘í•˜ê³  "TABLE_END"ë¡œ ëë‚´ì„¸ìš”.
            5. ë¹ˆ ì…€ì€ ë¹ˆ ë¬¸ìì—´("")ë¡œ í‘œì‹œí•˜ì„¸ìš”.
            6. í‘œê°€ ì—†ìœ¼ë©´ "NO_TABLES_FOUND"ë¼ê³  ì‘ë‹µí•˜ì„¸ìš”.

            ì‘ë‹µì€ CSV í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶„ì„ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            """
            mime_type = "application/pdf"
        else:  # ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°
            prompt = """
            ì´ ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í‘œë¥¼ ì°¾ì•„ ì •í™•í•œ CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
            ì´ë¯¸ì§€ê°€ 90ë„ íšŒì „ë˜ì–´ ìˆë”ë¼ë„ ì•Œì•„ì„œ ì¸ì‹í•˜ê³  í‘œì˜ ë‚´ìš©ì„ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

            ì¶”ì¶œ ì‹œ ë‹¤ìŒ ì§€ì¹¨ì„ ì² ì €íˆ ë”°ë¼ì£¼ì„¸ìš”:
            1. ì´ë¯¸ì§€ì— ìˆëŠ” ëª¨ë“  í‘œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ëª¨ë“  ìœ í˜•ì˜ í‘œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
               - ì¬ë¬´ì œí‘œ/ì¬ë¬´ìƒíƒœí‘œ/ëŒ€ì°¨ëŒ€ì¡°í‘œ (ìœ ë™ìì‚°, ë¹„ìœ ë™ìì‚°, ìì‚°ì´ê³„, ë¶€ì±„, ìë³¸ ë“±)
               - ì†ìµê³„ì‚°ì„œ (ë§¤ì¶œì•¡, ë§¤ì¶œì›ê°€, íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„, ì˜ì—…ì´ìµ, EBITDA ë“±)
               - í˜„ê¸ˆíë¦„í‘œ (ì˜ì—…í™œë™, íˆ¬ìí™œë™, ì¬ë¬´í™œë™ í˜„ê¸ˆíë¦„ ë“±)
               - ìë³¸ë³€ë™í‘œ
               - ì£¼ìš” íˆ¬ìì§€í‘œ (ì„±ì¥ì„±, ìˆ˜ìµì„±, EPS, PER, ROE ë“±)
               - ê·¸ ì™¸ ëª¨ë“  ìˆ«ìë‚˜ ë°ì´í„°ê°€ í¬í•¨ëœ í‘œ
            
            2. ê° í‘œì˜ êµ¬ì¡°ì™€ í˜•ì‹ì„ ì •í™•í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”:
               - ì—°ë„ë³„ ì¹¼ëŸ¼ êµ¬ì¡° ìœ ì§€ (í‘œì— ìˆëŠ” ëª¨ë“  ì—°ë„ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ)
               - ëª¨ë“  í–‰ê³¼ ì—´ì„ ëˆ„ë½ ì—†ì´ í¬í•¨ (ê¸ˆì•¡, ë¹„ìœ¨, ìˆ«ìê°’ ë“±)
               - í‘œì˜ ì›ë˜ êµ¬ì¡°ë¥¼ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ìœ ì§€
               - ìŒìˆ˜ ê°’ì€ "-" ê¸°í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ì›ë˜ í˜•íƒœë¡œ ìœ ì§€
               - ê´„í˜¸ ì•ˆì˜ ìˆ«ì(ì†ì‹¤/ë§ˆì´ë„ˆìŠ¤ í‘œì‹œ)ë„ ìŒìˆ˜ë¡œ ì ì ˆíˆ ë³€í™˜
            
            3. í‘œ ì „ì²´ë¥¼ ì™„ì „íˆ ì¶”ì¶œí•˜ì„¸ìš”:
               - í‘œ ìƒë‹¨ì˜ ì œëª©ê³¼ ë¶€ì œëª©ë„ ê°€ëŠ¥í•˜ë©´ í¬í•¨
               - í‘œ ë‚´ì˜ ëª¨ë“  ì¹´í…Œê³ ë¦¬ì™€ í•­ëª©ëª…ì„ ì •í™•í•˜ê²Œ í¬í•¨
               - í‘œ í•˜ë‹¨ì˜ ì£¼ì„ì´ë‚˜ ì¶œì²˜ ì •ë³´ë„ ê°€ëŠ¥í•˜ë©´ í¬í•¨
            
            4. ê° í‘œë§ˆë‹¤ "TABLE_START"ë¡œ ì‹œì‘í•˜ê³  "TABLE_END"ë¡œ ëë‚´ì„¸ìš”.
            5. ë¹ˆ ì…€ì€ ë¹ˆ ë¬¸ìì—´("")ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.
            6. í‘œê°€ ì—†ìœ¼ë©´ "NO_TABLES_FOUND"ë¼ê³  ì‘ë‹µí•˜ì„¸ìš”.

            ì‘ë‹µì€ CSV í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶„ì„ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ëª¨ë“  í‘œì™€ ë°ì´í„°ë¥¼ ì™„ì „í•˜ê³  ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤.
            """
            # ì´ë¯¸ì§€ íŒŒì¼ MIME íƒ€ì… ì„¤ì •
            if file_type.lower() in ["jpg", "jpeg"]:
                mime_type = "image/jpeg"
            elif file_type.lower() == "png":
                mime_type = "image/png"
            else:
                mime_type = f"image/{file_type.lower()}"
        
        # ê°œë°œì ëª¨ë“œì—ì„œ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if st.session_state.get('developer_mode', False) and st.session_state.get('custom_prompt'):
            prompt = st.session_state.get('custom_prompt')
            st.info("ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # API í˜¸ì¶œ ë¡œì§
        for attempt in range(max_retries):
            try:
                with st.spinner(f"Gemini APIë¡œ í‘œ ì¶”ì¶œ ì¤‘... (ì‹œë„ {attempt+1}/{max_retries})"):
                    model = genai.GenerativeModel(
                        gemini_model,
                        generation_config=genai.GenerationConfig(
                            temperature=temperature,  # ì„¤ì •ëœ ì˜¨ë„ ì‚¬ìš©
                            top_p=0.95,
                            max_output_tokens=max_tokens,  # ì„¤ì •ëœ í† í° ìˆ˜ ì‚¬ìš©
                        )
                    )
                    
                    response = model.generate_content([
                        prompt, 
                        {
                            "mime_type": mime_type,
                            "data": file_bytes
                        }
                    ])
                    result = response.text
                    
                    # ë””ë²„ê¹… ëª¨ë“œ ì¶œë ¥ (ì˜µì…˜)
                    if st.session_state.get('developer_mode', False):
                        st.text_area("API ì‘ë‹µ ì›ë³¸", result, height=200)
                    
                    if "NO_TABLES_FOUND" in result:
                        return []
                    
                    # ê²°ê³¼ ì²˜ë¦¬ ì½”ë“œ (CSV íŒŒì‹± ë“±)
                    tables_data = []
                    table_pattern = r"TABLE_START\s*(.*?)\s*TABLE_END"
                    matches = re.findall(table_pattern, result, re.DOTALL)
                    
                    for table_idx, table_csv in enumerate(matches):
                        if table_csv.strip():
                            try:
                                # ë¶ˆí•„ìš”í•œ ë¹ˆ ê³µê°„ ë° ë”°ì˜´í‘œ ì •ë¦¬
                                table_csv = re.sub(r'\s*"\s*,\s*', '",', table_csv)
                                table_csv = re.sub(r'\s*,\s*"\s*', ',"', table_csv)
                                
                                # CSV íŒŒì‹±
                                table_data = pd.read_csv(
                                    io.StringIO(table_csv.strip()), 
                                    skipinitialspace=True,
                                    on_bad_lines='warn',
                                    quoting=1,  # QUOTE_ALL ëª¨ë“œ ì‚¬ìš©í•˜ì—¬ ë”°ì˜´í‘œ ì²˜ë¦¬ ê°œì„ 
                                    dtype=str  # ëª¨ë“  ì—´ì„ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
                                )
                                
                                # ë¹ˆ ì—´/í–‰ ì œê±°
                                table_data = table_data.dropna(how='all', axis=0).dropna(how='all', axis=1)
                                
                                # ëª¨ë“  ì—´ì´ Unnamedì¸ ê²½ìš° í—¤ë” ì—†ì´ ì²˜ë¦¬
                                if all('Unnamed' in str(col) for col in table_data.columns):
                                    table_data.columns = [f'Column_{i}' for i in range(len(table_data.columns))]
                                
                                # ì›ë³¸ ë°ì´í„° ì €ì¥
                                original_df = table_data.copy()
                                
                                # ê²°ê³¼ì— ì¶”ê°€ - ì¬êµ¬ì„±ì´ ë¶ˆí•„ìš”í•œ ê²½ìš° ì›ë³¸ ë°ì´í„°ë¥¼ ë°”ë¡œ ì‚¬ìš©
                                tables_data.append({
                                    'index': table_idx,
                                    'df': original_df,
                                    'original_df': original_df  # ì›ë³¸ ë°ì´í„°ë„ ì €ì¥
                                })
                            except Exception as csv_error:
                                st.warning(f"í‘œ {table_idx+1} CSV íŒŒì‹± ì˜¤ë¥˜: {csv_error}")
                                
                                # íŒŒì‹± ì˜¤ë¥˜ ë³µêµ¬ ì‹œë„
                                try:
                                    # ì‰¼í‘œ ë¶„ë¦¬ ë¬¸ì œ í•´ê²° ì‹œë„
                                    fixed_csv = re.sub(r'("[^"]*),([^"]*")', r'\1COMMA\2', table_csv)
                                    fixed_csv = fixed_csv.replace('COMMA', ',')
                                    
                                    table_data = pd.read_csv(
                                        io.StringIO(fixed_csv.strip()),
                                        skipinitialspace=True,
                                        on_bad_lines='skip',
                                        quoting=3,  # QUOTE_NONE
                                        dtype=str
                                    )
                                    
                                    if not table_data.empty:
                                        original_df = table_data.copy()
                                        tables_data.append({
                                            'index': table_idx,
                                            'df': original_df,
                                            'original_df': original_df,
                                            'recovery': True
                                        })
                                    else:
                                        raise Exception("ë³µêµ¬ëœ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                                except:
                                    # ì›ë³¸ CSV í…ìŠ¤íŠ¸ ì €ì¥ (ë””ë²„ê¹…ìš©)
                                    error_df = pd.DataFrame({'original_csv': [table_csv.strip()]})
                                    tables_data.append({
                                        'index': table_idx,
                                        'df': error_df,
                                        'error': True
                                    })
                    
                    return tables_data
                    
            except GoogleAPIError as e:
                if attempt < max_retries - 1:
                    delay = 2 * (attempt + 1)
                    st.warning(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. {delay}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(delay)
                else:
                    st.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    return []
            except Exception as e:
                st.error(f"í‘œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return []
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return []

# í‘œê°€ ê³„ì•½ í…Œì´ë¸” í˜•ì‹ì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
def is_contract_table(df):
    """
    í‘œê°€ ê³„ì•½ í…Œì´ë¸” í˜•ì‹(í˜¸ì‹¤, ê³„ì•½ì, ë©´ì  ë“±ì˜ ì •ë³´)ì¸ì§€ í™•ì¸
    
    Args:
        df (DataFrame): í™•ì¸í•  ë°ì´í„°í”„ë ˆì„
    
    Returns:
        bool: ê³„ì•½ í…Œì´ë¸” í˜•ì‹ì´ë©´ True, ì•„ë‹ˆë©´ False
    """
    if df is None or df.empty:
        return False
    
    # ê³„ì•½ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ì‚¬
    contract_keywords = ['í˜¸ì‹¤', 'ê³„ì•½ì', 'ë©´ì ', 'ë¶„ì–‘ëŒ€ê¸ˆ', 'ë‚©ë¶€', 'ê³„ì•½ê¸ˆ', 'ì¤‘ë„ê¸ˆ', 'ì”ê¸ˆ']
    
    # ì»¬ëŸ¼ëª…ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    columns = [str(col).lower() for col in df.columns]
    column_match = any(keyword in ' '.join(columns).lower() for keyword in contract_keywords)
    
    # ë°ì´í„°ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    data_match = False
    if len(df) > 0:
        # ì²« 10ê°œ í–‰ë§Œ ê²€ì‚¬ (ì„±ëŠ¥ìƒ ì´ìœ )
        sample = df.head(10)
        for col in sample.columns:
            # ê° ì»¬ëŸ¼ì˜ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ê²€ì‚¬
            col_data = ' '.join(sample[col].astype(str).tolist()).lower()
            if any(keyword in col_data for keyword in contract_keywords):
                data_match = True
                break
    
    # í‘œ í˜•íƒœ ê²€ì‚¬ (ì¬ë¬´ì œí‘œ ê°™ì€ ë³µì¡í•œ í‘œëŠ” ì¼ë°˜ì ìœ¼ë¡œ í–‰ì´ ë§ê³  ì—´ì´ ë§ìŒ)
    is_small_table = len(df) < 20 and len(df.columns) < 10
    
    # ê³„ì•½ í…Œì´ë¸”ë¡œ íŒë‹¨í•˜ëŠ” ì¡°ê±´: í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆê³  ì‘ì€ í‘œì—¬ì•¼ í•¨
    return (column_match or data_match) and is_small_table

# í‘œ ìœ í˜•ì„ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
def detect_table_type(df):
    """
    í‘œ ìœ í˜•ì„ ê°ì§€í•˜ëŠ” í•¨ìˆ˜ (ì¬ë¬´ìƒíƒœí‘œ, ì†ìµê³„ì‚°ì„œ, í˜„ê¸ˆíë¦„í‘œ ë“±)
    
    Args:
        df (DataFrame): ê°ì§€í•  ë°ì´í„°í”„ë ˆì„
    
    Returns:
        str: ê°ì§€ëœ í‘œ ìœ í˜• ('ì¬ë¬´ìƒíƒœí‘œ', 'ì†ìµê³„ì‚°ì„œ', 'í˜„ê¸ˆíë¦„í‘œ', 'ê¸°íƒ€')
    """
    if df is None or df.empty:
        return 'ì•Œ ìˆ˜ ì—†ìŒ'
    
    # í‘œ ìœ í˜•ë³„ í‚¤ì›Œë“œ
    table_type_keywords = {
        'ì¬ë¬´ìƒíƒœí‘œ': ['ì¬ë¬´ìƒíƒœí‘œ', 'ëŒ€ì°¨ëŒ€ì¡°í‘œ', 'ìì‚°', 'ë¶€ì±„', 'ìë³¸', 'ìœ ë™ìì‚°', 'ë¹„ìœ ë™ìì‚°', 'ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„'],
        'ì†ìµê³„ì‚°ì„œ': ['ì†ìµê³„ì‚°ì„œ', 'ë§¤ì¶œì•¡', 'ë§¤ì¶œì›ê°€', 'ë§¤ì¶œì´ì´ìµ', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'EBITDA', 'íŒë§¤ë¹„', 'ê´€ë¦¬ë¹„'],
        'í˜„ê¸ˆíë¦„í‘œ': ['í˜„ê¸ˆíë¦„í‘œ', 'ì˜ì—…í™œë™', 'íˆ¬ìí™œë™', 'ì¬ë¬´í™œë™', 'í˜„ê¸ˆíë¦„', 'ê¸°ì´ˆí˜„ê¸ˆ', 'ê¸°ë§í˜„ê¸ˆ'],
        'íˆ¬ìì§€í‘œ': ['PER', 'ROA', 'ROE', 'EPS', 'BPS', 'ì„±ì¥ì„±', 'ìˆ˜ìµì„±', 'ì•ˆì •ì„±', 'ì£¼ë‹¹ìˆœì´ìµ']
    }
    
    # ì»¬ëŸ¼ê³¼ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨
    table_text = ' '.join([str(col) for col in df.columns])
    
    # ë°ì´í„°ì—ì„œ ì²« 20ê°œ í–‰ë§Œ ìƒ˜í”Œë§í•˜ì—¬ ë¬¸ìì—´ë¡œ í•©ì¹¨
    if len(df) > 0:
        sample = df.head(20)
        for col in sample.columns:
            try:
                table_text += ' ' + ' '.join(sample[col].astype(str).tolist())
            except:
                pass
    
    table_text = table_text.lower()
    
    # ê° ìœ í˜•ë³„ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    type_scores = {}
    for table_type, keywords in table_type_keywords.items():
        score = sum(1 for keyword in keywords if keyword.lower() in table_text)
        type_scores[table_type] = score
    
    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ìœ í˜• ì„ íƒ
    max_score_type = max(type_scores.items(), key=lambda x: x[1])
    
    # ìµœì†Œ ì ìˆ˜ ì„ê³„ê°’ ì„¤ì • (ìµœì†Œ 2ê°œ ì´ìƒì˜ í‚¤ì›Œë“œê°€ ë§¤ì¹­ë˜ì–´ì•¼ í•¨)
    if max_score_type[1] >= 2:
        return max_score_type[0]
    else:
        return 'ê¸°íƒ€'

# í‘œë¥¼ ì ì ˆí•˜ê²Œ ê°€ê³µí•˜ëŠ” í•¨ìˆ˜
def process_table_by_type(df, table_type):
    """
    í‘œ ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ í›„ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        df (DataFrame): ì²˜ë¦¬í•  ë°ì´í„°í”„ë ˆì„
        table_type (str): í‘œ ìœ í˜• ('ì¬ë¬´ìƒíƒœí‘œ', 'ì†ìµê³„ì‚°ì„œ', 'í˜„ê¸ˆíë¦„í‘œ', 'ê¸°íƒ€')
    
    Returns:
        DataFrame: ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    """
    if df is None or df.empty:
        return df
    
    # ëª¨ë“  ì—´ê³¼ í–‰ì—ì„œ ê³µë°± ì œê±°
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    
    # ë¹ˆ ì—´ê³¼ ë¹ˆ í–‰ ì œê±°
    df = df.dropna(how='all', axis=0).dropna(how='all', axis=1)
    
    # í‘œ ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¦¬
    if table_type in ['ì¬ë¬´ìƒíƒœí‘œ', 'ì†ìµê³„ì‚°ì„œ', 'í˜„ê¸ˆíë¦„í‘œ']:
        # ìˆ«ì ë°ì´í„° ì •ë¦¬
        # 1) ì²œë‹¨ìœ„ êµ¬ë¶„ì(ì‰¼í‘œ) ì œê±°
        # 2) ê´„í˜¸ë¡œ í‘œì‹œëœ ìŒìˆ˜ë¥¼ "-" ê¸°í˜¸ë¡œ ë³€í™˜
        for col in df.columns:
            if col != df.columns[0]:  # ì²« ë²ˆì§¸ ì—´ì€ í•­ëª©ëª…ì´ë¯€ë¡œ ì œì™¸
                df[col] = df[col].apply(lambda x: process_numeric_value(x) if pd.notna(x) else x)
    
    return df

# ìˆ«ì ê°’ ì²˜ë¦¬ í•¨ìˆ˜
def process_numeric_value(value):
    """
    ìˆ«ì ê°’ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        value: ì²˜ë¦¬í•  ê°’
    
    Returns:
        ì²˜ë¦¬ëœ ê°’
    """
    if not isinstance(value, str):
        return value
    
    # ì²œë‹¨ìœ„ êµ¬ë¶„ì(ì‰¼í‘œ) ì œê±°
    value = value.replace(',', '')
    
    # ê´„í˜¸ë¡œ í‘œì‹œëœ ìŒìˆ˜ë¥¼ "-" ê¸°í˜¸ë¡œ ë³€í™˜
    if value.startswith('(') and value.endswith(')'):
        value = '-' + value[1:-1]
    
    return value



def main():
    st.title("PDF/ì´ë¯¸ì§€ í‘œ ì¶”ì¶œ ë° CSV ë³€í™˜")
    
    # API í‚¤ ì„¤ì • ë¡œì§ ê°œì„ 
    api_key = get_api_key()
    
    # ì‚¬ì´ë“œë°”ì— ê³ ê¸‰ ì„¤ì • ì¶”ê°€
    with st.sidebar:
        st.header("ê³ ê¸‰ ì„¤ì •")
        
        # ì¶”ì¶œ í’ˆì§ˆ ì„¤ì •
        st.session_state.extraction_quality = st.radio(
            "ì¶”ì¶œ í’ˆì§ˆ",
            options=["ë†’ìŒ (ëŠë¦¼)", "ê· í˜•", "ë¹ ë¦„"],
            index=1  # ê¸°ë³¸ê°’ì€ 'ê· í˜•'
        )
        
        # ì¬êµ¬ì„± ì˜µì…˜ ì¶”ê°€
        st.session_state.restructure_table = st.checkbox(
            "í‘œ ì¬êµ¬ì„±",
            value=False,
            help="í‘œ êµ¬ì¡°ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤. íŠ¹ì • í˜•ì‹(ê³„ì•½ì„œ ë“±)ì˜ í‘œì— ìœ ìš©í•˜ì§€ë§Œ, ì¬ë¬´ì œí‘œ ê°™ì€ ë³µì¡í•œ í‘œì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
        )
        
        # ê°œë°œì ëª¨ë“œ ì„¤ì •
        developer_mode = st.checkbox("ê°œë°œì ëª¨ë“œ")
        if developer_mode:
            st.session_state.developer_mode = True
            st.session_state.custom_prompt = st.text_area(
                "ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸",
                value=st.session_state.get('custom_prompt', ''),
                height=200
            )
        else:
            st.session_state.developer_mode = False
    
    # API í‚¤ ì…ë ¥ ì²˜ë¦¬
    if not api_key:
        st.session_state["api_key"] = st.text_input("Google API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
        api_key = st.session_state["api_key"]
        if not api_key:
            st.warning("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()
    else:
        # API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìœ¼ë©´, Gemini API ì´ˆê¸°í™”
        if not setup_gemini_api(api_key):
            st.error("API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜, Gemini API ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.session_state.pop("api_key", None)  # ì˜ëª»ëœ API í‚¤ ì œê±°
            st.stop()
        st.success("API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # ëª¨ë¸ ì„ íƒ
    gemini_model = st.selectbox("Gemini ëª¨ë¸", ["gemini-1.5-pro", "gemini-1.5-flash"])
    
    # íŒŒì¼ íƒ€ì… ë° íŒŒì¼ ì—…ë¡œë” ì„¤ì •
    file_type = st.radio("íŒŒì¼ íƒ€ì… ì„ íƒ", ["PDF íŒŒì¼", "ì´ë¯¸ì§€ íŒŒì¼"], horizontal=True)
    st.subheader(f"{file_type} ì—…ë¡œë“œ")
    if file_type == "PDF íŒŒì¼":
        uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")
        file_format = "pdf"
    else:
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png", "bmp", "webp"])
        if uploaded_file is not None:
            file_format = uploaded_file.name.split('.')[-1].lower()
    
    if uploaded_file is not None:
        st.write({
            "íŒŒì¼ëª…": uploaded_file.name,
            "íŒŒì¼í¬ê¸°": f"{uploaded_file.size / 1024:.1f} KB",
            "íŒŒì¼íƒ€ì…": file_type
        })
        if file_type == "ì´ë¯¸ì§€ íŒŒì¼":
            st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
        
        file_name = os.path.splitext(uploaded_file.name)[0]
        
        # í‘œ ì¶”ì¶œ ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜ë¥¼ ë¯¸ë¦¬ ì´ˆê¸°í™”í•˜ì—¬ UnboundLocalErrorë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
        tables = []
        
        if st.button("í‘œ ì¶”ì¶œ ì‹œì‘", type="primary"):
            with st.spinner(f"{file_type}ì—ì„œ í‘œë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                # íŒŒì¼ ì²˜ë¦¬: PDFëŠ” ì²« í˜ì´ì§€, ì´ë¯¸ì§€ì˜ ê²½ìš° í•„ìš”í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©
                if file_type == "PDF íŒŒì¼":
                    processed_file = extract_first_page_pdf(uploaded_file)
                else:
                    processed_file = process_image_file(uploaded_file)
                    
                if processed_file is None:
                    st.error(f"{file_type} ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    st.stop()
                
                # Gemini APIë¥¼ í†µí•´ í‘œ ì¶”ì¶œ
                tables = extract_tables_from_file_directly(processed_file, file_format, gemini_model)
            
            timestamp = get_timestamp_filename()
            
            # ì¶”ì¶œëœ í‘œê°€ í•˜ë‚˜ ì´ìƒì¸ ê²½ìš° ì²˜ë¦¬
            if tables:
                st.success(f"{len(tables)}ê°œì˜ í‘œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                if len(tables) > 1:
                    tabs = st.tabs([f"í‘œ {i+1}" for i in range(len(tables))])
                    for tab_idx, tab in enumerate(tabs):
                        with tab:
                            table_data = next((t for t in tables if t['index'] == tab_idx), None)
                            if table_data:
                                df = table_data['df']
                                # íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
                                if table_data.get('error', False):
                                    st.warning("ì´ í‘œëŠ” íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì›ë³¸ CSV ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
                                    st.text_area("ì›ë³¸ CSV", df.get('original_csv', ''), height=200)
                                else:
                                    # í‘œ ì¬êµ¬ì„± ì˜µì…˜ì´ ì¼œì ¸ ìˆê³ , í‘œê°€ ì¼ì • í˜•ì‹ì„ ê°€ì§„ ê²½ìš°ì—ë§Œ ì¬êµ¬ì„±
                                    should_restructure = st.session_state.get('restructure_table', False)
                                    
                                    if should_restructure and is_contract_table(df):
                                        restructured_data = restructure_table_data(df)
                                        if isinstance(restructured_data, dict) and 'top_table' in restructured_data:
                                            st.subheader("ì¬êµ¬ì„±ëœ ë°ì´í„°")
                                            st.dataframe(restructured_data['top_table'], use_container_width=True)
                                            st.dataframe(restructured_data['bottom_table'], use_container_width=True)
                                            # ì¬êµ¬ì„±ëœ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
                                            df = restructured_data
                                        else:
                                            st.subheader("ì›ë³¸ ë°ì´í„° (ì¬êµ¬ì„± ì‹¤íŒ¨)")
                                            st.dataframe(df, use_container_width=True)
                                    else:
                                        st.subheader("ì›ë³¸ ë°ì´í„°")
                                        st.dataframe(df, use_container_width=True)
                                
                                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì²˜ë¦¬ (ê° íƒ­ ë³„ë¡œ ì²˜ë¦¬)
                                csv_filename = f"{file_name}_{timestamp}_table_{tab_idx+1}.csv"
                                if isinstance(df, dict) and 'combined' in df:
                                    csv = df['combined'].to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                                else:
                                    csv = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                                
                                st.download_button(
                                    label="CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                                    data=csv,
                                    file_name=csv_filename,
                                    mime='text/csv'
                                )
                else:
                    # ë‹¨ì¼ í‘œì¸ ê²½ìš°
                    st.subheader("ì¶”ì¶œëœ í‘œ")
                    df = tables[0]['df']
                    if tables[0].get('error', False):
                        st.warning("ì´ í‘œëŠ” íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì›ë³¸ CSV ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
                        st.text_area("ì›ë³¸ CSV", df.get('original_csv', ''), height=200)
                    else:
                        # í‘œ ì¬êµ¬ì„± ì˜µì…˜ì´ ì¼œì ¸ ìˆê³ , í‘œê°€ ì¼ì • í˜•ì‹ì„ ê°€ì§„ ê²½ìš°ì—ë§Œ ì¬êµ¬ì„±
                        should_restructure = st.session_state.get('restructure_table', False)
                        
                        if should_restructure and is_contract_table(df):
                            restructured_data = restructure_table_data(df)
                            if isinstance(restructured_data, dict) and 'top_table' in restructured_data:
                                st.subheader("ì¬êµ¬ì„±ëœ ë°ì´í„°")
                                st.dataframe(restructured_data['top_table'], use_container_width=True)
                                st.dataframe(restructured_data['bottom_table'], use_container_width=True)
                                # ì¬êµ¬ì„±ëœ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
                                df = restructured_data
                            else:
                                st.subheader("ì›ë³¸ ë°ì´í„° (ì¬êµ¬ì„± ì‹¤íŒ¨)")
                                st.dataframe(df, use_container_width=True)
                        else:
                            st.subheader("ì›ë³¸ ë°ì´í„°")
                            st.dataframe(df, use_container_width=True)
                    
                    csv_filename = f"{file_name}_{timestamp}_table_1.csv"
                    if isinstance(df, dict) and 'combined' in df:
                        csv = df['combined'].to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                    else:
                        csv = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                    
                    st.download_button(
                        label="CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=csv,
                        file_name=csv_filename,
                        mime='text/csv'
                    )
            else:
                st.warning(f"{file_type}ì—ì„œ í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if file_type == "PDF íŒŒì¼":
                    st.info("""
                    ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:
                    1. PDFê°€ í…ìŠ¤íŠ¸ ë ˆì´ì–´ë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš” (ìŠ¤ìº”ëœ ë¬¸ì„œëŠ” OCRì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤).
                    2. í‘œê°€ ì‹¤ì œë¡œ í‘œ í˜•ì‹ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
                    3. PDF íŒŒì¼ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ í•´ìƒë„ë¥¼ ë†’ì—¬ë³´ì„¸ìš”.
                    """)
                else:
                    st.info("""
                    ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:
                    1. ì´ë¯¸ì§€ í•´ìƒë„ê°€ ì¶©ë¶„íˆ ë†’ì€ì§€ í™•ì¸í•˜ì„¸ìš”.
                    2. ì´ë¯¸ì§€ê°€ íë¦¿í•˜ê±°ë‚˜ ì™œê³¡ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
                    3. í‘œê°€ ëª…í™•í•˜ê²Œ ë³´ì´ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
                    4. ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì„œ ì‹œë„í•´ë³´ì„¸ìš”.
                    """)
    else:
        st.info("ì—…ë¡œë“œí•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")

       
if __name__ == "__main__":
    main()
    